# M3239.004000.  ìì—°ì–´ ì²˜ë¦¬ì˜ ì‘ìš©: NLP and its recent progress.

## Links

ğŸ—“ [Course schedule](https://leejayyoon.github.io/nlp-gsds/course_schedule.csv)

ğŸ“•Â [Reference Texts](https://leejayyoon.github.io/nlp-gsds/#reference-texts)

ğŸ•°Â [Time & Location](https://leejayyoon.github.io/nlp-gsds/#time--location)

ğŸ‘¨ğŸ»â€ğŸ«Â [Instructor & TAs](https://leejayyoon.github.io/nlp-gsds/#instructor)
ğŸƒğŸ»â€â™‚ï¸Â [Course description](https://leejayyoon.github.io/nlp-gsds/#course-description)
ğŸ“ [Grading policy](https://leejayyoon.github.io/nlp-gsds/#grading-policy) 


## **Reference Texts**

No specific text book is required for this course but the following texts could be useful.  (First two are free online)

- Dan Jurafsky and James H. Martin,Â [Speech and Language Processing (3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/)
- Jacob Eisenstein,Â [Natural Language Processing](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)
- Masato Hagiwara, [Real-World Natural Language Processing](https://www.manning.com/books/real-world-natural-language-processing)

## Time & Location

- **Time:** Tue & Thu 3:30p-4:45p
- **Location:** Building 942, room 302 or virtually via Zoom.
- Zoom link will be provided through ETL and possibly via emails.

## Instructor

[Lee, Jay-Yoon](https://leejayyoon.github.io/) 

- email: lee.jayyoon@snu.ac.kr
- office: Building 942, Room 426.
- office hours: Tue 2:30-3:30p

## Teaching Assistants

- Song, Jonghyun (Head TA), [hyeongoon11@snu.ac.kr](mailto:hyeongoon11@snu.ac.kr)
    - Office hours: TBD
- Kim, Yikyung, [k2y1513@snu.ac.kr](mailto:k2y1513@snu.ac.kr)

## Course description

This course introduces core deep learning techniques used in modern natural language processing and visits recent advances and the challenges unresolved.

This course covers the following topics:

- How NLP utilizes representation learning.
- How problems in NLP motivated novel deep learning approaches such as attention and self-attention.
- Architectures: RNN, Sequence-to-sequence model, Transformer.
- Applications: word embedding, Language Model, core NLP (Parsing, SRL), QA and natural language generation (Summarization, Machine Translation, etc.) problems.
- Recent concerns: controllability, injection of constraints and knowledge, bias & fairness

## Grading policy

- **Final grade** will be determined as a weighted average of the assignments, midterm, and project.
    - Cutoffs for final grades will be approximately 97+ A+, 93+ A, 90+ A-, 87+ B+, 83+ B, 80+ B-, etc.
- **Assignments**: 70%  A+ (100), A (96), A- (92), B+ (88), B (85), B- (82), or below.
    - There will be four assignments.
- **Quiz**: 10%
- **Paper presentation**: 10%
- **Project (optional):** Assignment 3 & 4 can be replaced with project.
    - Project proposal & state-of-the-art reimplementation (Due date identical to Assignment 3 due)
    - Final report & presentation.
    - Teams of 2-3. Individual project requires permission from instructor.
    - Project grading
        - A+: Exceptional or surprising. Goes far beyond most other submissions.
        - A: A survey that covers all the major relevant papers in the field and a well-grounded project proposal based on this survey.
        - A-: The survey has a good analysis but is missing a few pieces of relevant related work, or is quite complete but is lacking in critical analysis or forward directions.
        - B+: The survey is either quite lacking in coverage or analysis, or is decent but not complete in both aspects.
        - B or B-: The survey is lacking in both coverage and analysis, but does make an attempt to cover some related research.
        - C+ or below: Clear lack of effort or incompleteness.